# -*- coding: utf-8 -*-
"""Car_Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IcjAid7LV65QfkHgQaHc-ntMLN14O6Yl
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
sns.set()

df = pd.read_csv('car data.csv')

df.head()

df.shape

df.describe().T

df.info()

cat_features = [feature for feature in df.columns if df[feature].dtype == 'O']
print("number of categorical features are: ", len(cat_features))

df.isnull().sum()

df['Current_Year'] = 2020

df['Age_of_Car'] = df['Current_Year'] - df['Year']

df.head()

df = df.drop(['Car_Name','Year','Current_Year'], axis = 1)

df.head()

df = pd.get_dummies(df, drop_first= True)

df.head()

sns.pairplot(df)

corr = df.corr()
top_features = corr.index
plt.figure(figsize= (12,6))
sns.heatmap(corr, annot= True, cmap = 'RdYlGn')

x = df.iloc[:,1:]

y = df.iloc[:,0]

x.head()

y.head()

#Feature Im[ortance
from sklearn.ensemble import ExtraTreesRegressor
feat_model = ExtraTreesRegressor()
feat_model.fit(x,y)

feat_model.feature_importances_

#Plot of Feature importance
feature_imp = pd.Series(feat_model.feature_importances_, index = x.columns)
feature_imp.nlargest(5).plot(kind = 'barh')
plt.show()

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2, random_state = 6)

from sklearn.ensemble import RandomForestRegressor
regressor = RandomForestRegressor()

#HyperParameter tuning
n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]
max_depth = [int(x) for x in np.linspace(start = 5, stop = 30, num = 6)]
max_features = ['auto', 'sqrt']
min_samples_split = [2,5,10,20,50,100]
min_samples_leaf = [1,2,5,7,10]

from sklearn.model_selection import RandomizedSearchCV
random_grid = {'n_estimators':n_estimators,
               'max_depth':max_depth,
               'max_features':max_features,
               'min_samples_split':min_samples_split,
               'min_samples_leaf':min_samples_leaf}
print(random_grid)

rand_cv = RandomizedSearchCV(estimator = regressor, param_distributions=random_grid, scoring= 'neg_mean_squared_error', cv = 10  )

rand_cv.fit(x_train, y_train)

print(rand_cv.best_estimator_)

print(rand_cv.best_params_)

final_regressor = RandomForestRegressor(n_estimators=1200, max_depth= 10, min_impurity_split=2, min_samples_leaf=2,max_features='auto')

final_regressor.fit(x_train, y_train)

y_pred = final_regressor.predict(x_test)

pred_plot = sns.distplot(y_test - y_pred)

import pickle
file = open('car_prediction_model.pkl','wb')
pickle.dump(final_regressor,file)









